dataset:
  dir:
    train: 
      - "/media/andjela/SeagatePor/dataset_RigidReg_1.5_f2/train"
    valid: ""
    test: "/media/andjela/SeagatePor/dataset_RigidReg_1.5_f2/test" 
  format: "nifti"
  type: "grouped" # paired / unpaired / grouped
  labeled: false # next line if true : sample_label: "all"  # "sample", "all" or None
  intra_group_prob: 1 #for intra-group samples
  intra_group_option: "forward" # forward / backward / unconstrained
  sample_image_in_group: false # generates all possible pairs with false, if true only one image pair will be yielded for each group, so one epoch has num_groups pairs of data
  image_shape: [153, 153, 125]

train:
  # define neural network structure
  method: "ddf" # the registration method, value should be ddf / dvf / conditional(predicts ROI)
  backbone:
    name: "unet"
    num_channel_initial: 8
    depth: 2
    pooling: false
    concat_skip: true
    # LocalNet implement
    # name: "local" # value should be local / global / unet
    # num_channel_initial: 16 # number of initial channel in local net, controls the size of the network
    # # depth parameter, depth = 2 is not required here
    # extract_levels: [0, 1, 2]

  # define the loss function for training
  loss:
    image:
      name: "lncc" #num_bins = 23 and sigma_ratio = 0.5 by default
      weight: 1.0
     #add - under image if multiple loss function needed
    label:
      weight: 0.0
      name: "dice"
      scales: [0, 1, 2, 4, 8, 16]
    regularization:
      weight: 1.0 # weight of regularization loss
      name: "gradient" # options include "bending", "gradient"
      l1: false # if false calculates L2-norm gradient loss of the ddf, if true L1-norm calculated

  # define the optimizer
  optimizer:
    name: "Adam"
    learning_rate: 1.0e-4

  # how the data loader feeds data into the model
  preprocess: 
    batch_size: 2 #used 4 for 117 training images in grouped_mr_heart demo
    shuffle_buffer_num_batch: 1 # shuffle_buffer_size = batch_size * shuffle_buffer_num_batch quantity of pre-loaded data into memory

  epochs: 250 # number of training epochs
  save_period: 25 # the model will be saved every `save_period` epochs.

